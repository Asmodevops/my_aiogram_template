services:
  postgres:
    image: postgres:17-alpine
    container_name: postgres
    env_file:
      - .env
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - ./postgres-data:/var/lib/postgresql/data
    ports:
      - ${DB_PORT:-5432}:5432
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}" ]
      interval: 5s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
        compress: "true"
    networks:
      - app_network

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    env_file:
      - .env
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
    ports:
      - "${PGADMIN_PORT}:80"
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
        compress: "true"
    networks:
      - app_network

  redis:
    image: redis:7.4-alpine
    container_name: redis
    env_file:
      - .env
    volumes:
      - ./redis-data:/data
    restart: unless-stopped
    ports:
      - "${REDIS_PORT}:6379"
    command: [ "redis-server", "--appendonly", "yes", "--requirepass", "${REDIS_PASSWORD}" ]
    healthcheck:
      test: [ "CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "PING" ]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 5s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
        compress: "true"
    networks:
      - app_network

  nats:
    image: nats:latest
    container_name: nats
    entrypoint: /nats-server
    command: "-c /config/server.conf"
    ports:
      - "${NATS_PORT}:4222"
      - "${NATS_MONITORING_PORT}:8222"
    volumes:
      - ./nats/nats-data:/data
      - ./config/nats/server.conf:/config/server.conf
    healthcheck:
      test: ["CMD", "nats-server", "-sl"]
      interval: 5s
      timeout: 3s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
        compress: "true"
    networks:
      - app_network

  nats-nui:
    image: ghcr.io/nats-nui/nui:latest
    container_name: nats-nui
    env_file:
      - .env
    ports:
      - "${NUI_PORT}:31311"
    environment:
      NUI_USERNAME: ${NUI_USERNAME}
      NUI_PASSWORD: ${NUI_PASSWORD}
    volumes:
      - ./nui-data/db:/db
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
        compress: "true"
    networks:
      - app_network
    depends_on:
      nats:
        condition: service_healthy

  tg_bot:
    &bot
    build: .
    restart: on-failure
    env_file:
      - .env
    command: >
      bash -c "uv run alembic upgrade head && uv run main.py"
    depends_on:
      - postgres
      - redis
      - nats
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
        compress: "true"
    networks:
      - app_network

  taskiq-worker:
    <<: *bot
    ports: []
    command: >
      bash -c "uv run taskiq worker app.services.scheduler.taskiq_broker:taskiq_broker -fsd --no-configure-logging"

  taskiq-scheduler:
    <<: *bot
    ports: []
    command: >
      bash -c "uv run taskiq scheduler app.services.scheduler.taskiq_broker:scheduler -fsd --no-configure-logging"


networks:
  app_network:
    name: app_network
